{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 타이타닉 생존 분석: 머신러닝 모델링\n",
    "\n",
    "## 1. 데이터 준비 및 전처리\n",
    "\n",
    "### 1.1 필요한 라이브러리 및 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 기본 정보:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   survived       891 non-null    int64  \n",
      " 1   pclass         891 non-null    int64  \n",
      " 2   sex            891 non-null    object \n",
      " 3   age            891 non-null    float64\n",
      " 4   sibsp          891 non-null    int64  \n",
      " 5   parch          891 non-null    int64  \n",
      " 6   fare           891 non-null    float64\n",
      " 7   embarked       891 non-null    object \n",
      " 8   who            891 non-null    object \n",
      " 9   adult_male     891 non-null    bool   \n",
      " 10  deck           891 non-null    object \n",
      " 11  alone          891 non-null    bool   \n",
      " 12  family_size    891 non-null    int64  \n",
      " 13  family_type    891 non-null    object \n",
      " 14  age_group      891 non-null    object \n",
      " 15  fare_category  891 non-null    object \n",
      "dtypes: bool(2), float64(2), int64(5), object(7)\n",
      "memory usage: 99.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('../data/processed/titanic_processed.csv')\n",
    "\n",
    "# 기본 정보 확인\n",
    "print(\"데이터셋 기본 정보:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 특성 선택 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "선택된 특성: 28\n",
      "\n",
      "처음 5개 특성: ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
      "\n",
      "데이터 shape:\n",
      "X_train shape: (712, 28)\n",
      "X_test shape: (179, 28)\n"
     ]
    }
   ],
   "source": [
    "# 범주형 변수 인코딩\n",
    "df_encoded = pd.get_dummies(df, columns=['sex', 'embarked', 'deck', 'age_group', 'fare_category'])\n",
    "\n",
    "# 사용할 특성 선택\n",
    "features = ['pclass', 'age', 'sibsp', 'parch', 'fare', 'family_size'] + \\\n",
    "          [col for col in df_encoded.columns if 'sex_' in col or \n",
    "                                               'embarked_' in col or \n",
    "                                               'deck_' in col or \n",
    "                                               'age_group_' in col or \n",
    "                                               'fare_category_' in col]\n",
    "\n",
    "X = df_encoded[features]\n",
    "y = df_encoded['survived']\n",
    "\n",
    "# 훈련/테스트 세트 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 특성 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n선택된 특성:\", len(features))\n",
    "print(\"\\n처음 5개 특성:\", features[:5])\n",
    "print(\"\\n데이터 shape:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 머신러닝 모델 구현 및 평가\n",
    "\n",
    "### 2.1 기본 모델 구현 및 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "로지스틱 회귀 성능 평가:\n",
      "정확도 (Accuracy): 0.7877094972067039\n",
      "정밀도 (Precision): 0.7368421052631579\n",
      "재현율 (Recall): 0.7567567567567568\n",
      "F1 점수: 0.7466666666666667\n",
      "\n",
      "혼동 행렬:\n",
      "[[85 20]\n",
      " [18 56]]\n",
      "\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       105\n",
      "           1       0.74      0.76      0.75        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.78      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n",
      "\n",
      "의사결정나무 성능 평가:\n",
      "정확도 (Accuracy): 0.7653631284916201\n",
      "정밀도 (Precision): 0.7\n",
      "재현율 (Recall): 0.7567567567567568\n",
      "F1 점수: 0.7272727272727273\n",
      "\n",
      "혼동 행렬:\n",
      "[[81 24]\n",
      " [18 56]]\n",
      "\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.79       105\n",
      "           1       0.70      0.76      0.73        74\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.76      0.76      0.76       179\n",
      "weighted avg       0.77      0.77      0.77       179\n",
      "\n",
      "\n",
      "랜덤 포레스트 성능 평가:\n",
      "정확도 (Accuracy): 0.7932960893854749\n",
      "정밀도 (Precision): 0.7534246575342466\n",
      "재현율 (Recall): 0.7432432432432432\n",
      "F1 점수: 0.7482993197278912\n",
      "\n",
      "혼동 행렬:\n",
      "[[87 18]\n",
      " [19 55]]\n",
      "\n",
      "분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       105\n",
      "           1       0.75      0.74      0.75        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.79      0.79      0.79       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m evaluate_model(y_test, y_pred_rf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m랜덤 포레스트\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 특성 중요도 시각화 (랜덤 포레스트 기준)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     35\u001b[0m importances \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(rf\u001b[38;5;241m.\u001b[39mfeature_importances_, index\u001b[38;5;241m=\u001b[39mfeatures)\n\u001b[0;32m     36\u001b[0m importances \u001b[38;5;241m=\u001b[39m importances\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    모델 성능 평가 및 결과 출력 함수\n",
    "    \"\"\"\n",
    "    print(f\"\\n{model_name} 성능 평가:\")\n",
    "    print(\"정확도 (Accuracy):\", accuracy_score(y_true, y_pred))\n",
    "    print(\"정밀도 (Precision):\", precision_score(y_true, y_pred))\n",
    "    print(\"재현율 (Recall):\", recall_score(y_true, y_pred))\n",
    "    print(\"F1 점수:\", f1_score(y_true, y_pred))\n",
    "    print(\"\\n혼동 행렬:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n분류 보고서:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# 1. 로지스틱 회귀\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_log = log_reg.predict(X_test_scaled)\n",
    "evaluate_model(y_test, y_pred_log, \"로지스틱 회귀\")\n",
    "\n",
    "# 2. 의사결정나무\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "y_pred_dt = dt.predict(X_test_scaled)\n",
    "evaluate_model(y_test, y_pred_dt, \"의사결정나무\")\n",
    "\n",
    "# 3. 랜덤 포레스트\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "evaluate_model(y_test, y_pred_rf, \"랜덤 포레스트\")\n",
    "\n",
    "# 특성 중요도 시각화 (랜덤 포레스트 기준)\n",
    "plt.figure(figsize=(12, 6))\n",
    "importances = pd.Series(rf.feature_importances_, index=features)\n",
    "importances = importances.sort_values(ascending=True)\n",
    "importances.plot(kind='barh')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
